#### - 지시함수:
	$Ⅱ(\theta) = \begin{cases} 1 & \text{if } \theta가\ 참일때 \\ 0 & \text{if } \theta가 \ 거짓일때 \end{cases}$
	ex) Ⅱ(y = μ) 와 같이 사용. y가 μ가 아니면 0을 μ면 1을 반환.

#### - 사건의 확률 :
	
	  $Pr(A)$로 표현. $Pr(A)$ :사건 A가 참이라고 믿는 확률
	  $Pr(!A) = 1- Pr(A)$


##### - 사건의 결합확률(joint probablity) and연산
	
	 $Pr(A ∧ B) = Pr(A,B)$로 표현. A와 B가 독립이면 $Pr(A)*Pr(B)$로도 표현가능


#### - 사건의 합의 확률 OR연산
	
	
	  $Pr(A∨ B) = Pr(A) + Pr(B) - Pr(A^B)$
	
	조건부 확률(사건 A가 발생했을 때 사건 B가 일어날 확률)
	
	   $Pr(B|A) = Pr(A,B)/Pr(A)$ ⇒ A의 사건이 일어났을때의 사건 B가 일어날 확률
		
		ex) A = 탄산음료 먹을 확률, B = 콜라를 먹을 확률라고 가정할때
		
		P(B|A)는 탄산음료를 먹었을때 그 탄산음료가 콜라일 확률을 뜻함.
	

**확률변수(random variable)** ⇒ rv로 표현. 확률변수를 X라 할때 X의 값이 알려지지 않았거나 변할수 있음.

**Parameter(모수)** : 주로 여기선 θ로 표현. 인공신경망에서의 weight값으로 입력값이 아니라 인공신경망이 학습하여 얻는 수.

**이산확률변수** ⇒ sample space $X$가 유한하거나 가산적인 무한일때의 $X$

#### - PMF(Probablity Mass Function) 확률 질량 함수 :
	
	이산확률변수의 확률분포를 설명하는데 사용함.
	
	  └ 주사위 던지기, 동전 던지기와 같은 값이 유한하거나 셀 수 있는 경우
	
	
	이산적인 사건의 확률을 명확히 계산해야 할때 주로 사용.
	
	통계모델링, 데이터분석 및 의사결정 등에서 사용.
	
	PMF는 확률 변수 X의 확률
	
	$P(x) = Pr(X = x)$와 같이 표현
	
	조건 : 
	① $0 ≤ P(x) ≤ 1$
	② $Σ_X P(X) = 1$ (모든 P의 합은 1)
	
	
	연속확률변수 ⇒ X ∈ R 즉, X가 실숫값의 양수면 연속확률변수.

#### - CDF(Cumulative distribution fuction) 누적 분포 함수 :
	
	단조 비감소 함수.
	
	확률변수 X가 특정값 x이하일 확률을 나타내는 함수
	
	이산확률변수와 연속확률변수 모두에서 사용됨.
	
	확률 계산의 간소화, 이산 및 연속분포 분포 분석, 랜덤 변수 생성 등에서 사용됨.
	
	그리고, 서로 다른 분포를 비교하거나 데이터의 quantile(백분위수)를 구할때도 사용됨.
	
	$P(X) = Pr(X≤ x) = Σf(x)$
	
	$P(a<X≤b) = Pr(b)- Pr(a)$



#### - PDF(Probablity Density Function) 확률밀도함수 :

	특정구간 $[a,b]$에서 연속확률변수 X가 값을 가질 확률.
	
	이산확률변수와 달리 연속확률변수 X의 특정값에서의 확률은 0이므로 PDF를 사용.
	
	구간에서의 확률밀도를 구하므로 적분을 사용.
	
	$Pr(a<X≤b) = ∫^{b}_{a} p(x)dx$ 와 같이 표현.
	
	$p(x) = d/dx*P(x)$ ⇒ $p(x)$, PDF는 CDF의 도함수.
	
	그래서 위의 $Pr(a<X≤b)$은 $P(b)-P(a)$로 표현됨.
	
	조건 : 
	① 임의의 실수 x에서 p(x) ≥ 0
	② $∫^{∞}_{-∞} p(x)dx = 1$ (확률분포에서의 확률밀도함수의 총합은 1)


#### - 분포의 mode:

	가장 큰, 확률질량이나 확률밀도를 갖는 값. 최빈값이라고도 불림
	
	Pr(x)가 최대가 될때의 x값.
	
	x* = $argmax_x$ $Pr(x)$ 와 같이 표현.
	
	multimodal (다봉) ⇒ global maximum이 여러개 있는 상황. 머신러닝에선 여러종류의 데이터를 입력값으로 사용하는 것을 multimodal이라 함. modal은 데이터의 종류, 또는 형태.
	
	multimodal일때에는 mode가 유일하지 않을 수 있음. 또는 유일한 mode여도 잘 요약하지 못할 수 있음.


#### - 가중평균(weighted average):

	각각의 값에 “다른 weight”를 부여하여 구한 평균.
	
	일반적인 산술평균은 각각의 값에 모두 같은 weight를 부여.
	
	가중평균은 $Σ_{n}^{N}$$(값_n*weight_n)$ 으로 구함
	
	ex) ⇒ A 시험 : 80점 (weight 0.4) weight는 현재 시험의 중요도를 나타냄.
	
	
	 B 시험 : 97점 (weight 0.2)
	
	 C 시험 : 71점 (weight 0.4)라 가정하면 
	
	 가중평균 → 80*0.4 + 97*0.2 + 71*0.4 = 32 + 19.4 + 28.4 = 79.8


#### - 분포의 평균, 기댓값(Expectation) μ라고도 씀.

^bf7439

	분포의 가장 익숙한 특성. 분포의 평균은 가중평균을 사용.
	
	$E[X]$ ⇒ 가중평균
	
	기댓값이 가중평균인 이유 :
	
	기댓값은 확률변수가 가질 수 있는 모든 값을 그 값이 나타날 확률에 따라 가중치를 두어 계산하기 때문.
	
	즉, 각 값이 나타날 확률이 전부 다르기 때문에 값이 나타날 확률을 weight로 두어 기댓값을 구함.


##### - 이산 확률 변수 :

	$E[X] = Σ_x x*p(x)$ (이산확률변수 x는 확률변수의 값. pmf를 weight로 사용)


##### - 연속 확률 변수 :

	$E[X] =$ $\int_{X} xP(x)dx$ (연속확률변수 pdf를 weight로 사용)

##### - 기댓값의 여러가지 법칙들:
	
	기댓값은 선형 연산자 ⇒ $E[aX+b] = aE[X]+b$
	
	$E[E[X]] = E[X]$
	
	$E[X+Y] = E[X]+E[Y]$
	
	확률 변수 X,Y가 독립일때 ⇒ $E[XY] = E[X]E[Y]$
	
	$E[XY] = \Sigma_{i=1}^n(X_iY_i)p(X_i,Y_i)$



#### - Conditional Expectation(조건부 적률, 조건부 기댓값)

	특정 조건이 주어졌을때의 확률변수의 기댓값(평균). 기댓값은 평균.
	
	특정 사건이나 정보가 주어졌을때 확률 변수를 분석하는데 유용함.
	
	이산 확률 변수 ⇒ $E[X|Y = y] = ∑_x x*P(X= x | Y= y)$
	
	└ $P(X=x|Y=y)$은 Y =y일때의 X의 조건부 PMF.
	
	연속 확률 변수 ⇒ $E[X|Y=y] = ∫x*f_{X|Y}(x|y)dx$
	
	└ $f_{X|Y}f(x|y)$는 Y=y일때 X의 조건부 PDF
	
	$E[X] = E_Y[E[X|Y]]$
	
##### - 이산확률변수에서:

	$E_Y[E[X|Y]]$는 $E[X|Y]$를 $Y$ 분포에서의 평균을 낸것.
	
	$E_Y[E[X|Y]] = \Sigma_y(E[X|Y=y]*p(y)) = \Sigma_y(\Sigma_x(E[X=x|Y=y]*x)*p(y))$
	
##### - 연속확률변수에서:
	
	$E_Y[E[X|Y]] = \int_{-∞}^{∞}(E[X|Y=y]*p(y))dy = \int_{-∞}^{∞}(\int_{-∞}^{∞}(E[X=x|Y=y]*x)dx)*p(y)dy$
	

#### - 분포의 분산(variance):
${σ^2}$으로 표기. $V[X] = E[(X-μ)^2]$

	분포의 퍼짐을 나타내는 측도.



#### - 요약 통계량의 한계:

요약 통계량은 적률이라고도 볼 수 있음.

**요약통계량 :** 대량의 데이터를 몇개의 대표적인 수치로 요약하여 데이터의 중심 경향, 분산, 분포의 형태 또는 **변수 간의 관계를 간략히 설명하는 도구.**

##### 주요 요약 통계량 :

**중심 경향**: **데이터의 중심**을 나타내는 값.(평균, 중앙값, 최빈값)

**분산도** : 데이터가 얼마나 퍼져있는지.

**분산** : 데이터 값이 평균으로 부터 얼마나 떨어져 있는지의 평균 제곱.

**표준 편차**: 데이터의 퍼짐 정도를 직관적으로 보여줌.

**사분위수 범위(IQR)** : 데이터의 25번째 백분위수와 75번째 백분위수의 차이. outlier에 덜 민감.
	0~25% 범위와 75%~100%의 범위의 차이.

**요약통계량의 범위** : 최대값과 최소값 사이

**상관관계(correlation)**: 두 변수간의 **선형관계를 측정**.

**상관계수(Correlation Coefficient, ρ)**: -1~1사이의 값. **두 변수가 얼마나 선형적으로 관련 있는지를 나타냄**

###### 요약 통계량의 한계:

	분포의 모양을 반영하지 않음. 같은 평균과 분산을 가진 데이터셋이라도 분포가 다를 수 있음.
	
	ex) unimodal(단봉), bimodal(이봉)은 같은 평균과 분산을 가질 수 있지만 모양이 다름.
	
	Outlier 무시 : 이상치가 나타내는 데이터의 중요한 특성을 놓칠 수 있음.
	
	비선형 패턴 무시: 상관계수는 선형관계만 측정. 곡선 형태의 관계는 놓칠 수 있음.
	
	데이터의 구조적 차이 : 동일한 평균, 분산, 상관계수를 가지지만 시각화하면 다른 패턴을 보일 수 있음.

#### - 베이즈 규칙:

관측된 데이터 Y = y 가 주어졌을 때, 알 수 없는 변수 H의 가능한 값들에 대한 확률 분포를 계산하는 공식.

$Pr(H = h|Y = y) = Pr(H=h)Pr(Y=y|H=h)/Pr(Y=y)$

└ $Pr(h|y)*Pr(Y=y) = Pr(H=h)Pr(Y=y|H=h)$ = 사전 x Likelihood

$P(H=h)$ ⇒ 사전 분포. 데이터 Y를 보기 전에 H가 나올 확률. 즉, 데이터 Y를 고려하지 않은 H의 확률.

$P(Y|H=h)$ ⇒ 관측 분포. Likelihood ⇒ 가능성, 증거의 강도를 나타냄.

증거가 H를 얼마나 뒷받침하는지.
머신러닝에선 $P(Y | weight)$를 사용해 Label이 나올 확률이 높은 weight를 선택하도록 함.

**사후 ∝ 사전 × Likelihood : 사후확률은 사전확률x Likelihood에 비례함. P(y)는 상수이므로 무시**

Likelihood에 대한 설명 추가 필요.


#### - 시그모이드 함수:

머신러닝에서 **이진분류를 할때 사용**되는 함수.

0~1사이의 값을 가지는 함수로서 S자 형태를 가짐.

수식은 $\sigma(X) = 1/(1+e^-X)$ 로 표현됨.

여기서 **입력값 X는 log odds**라고 불림.

log odds는 odds(승산)에 log를 취한 것을 뜻함.

$odds= p/(1-p)$ ⇒ 여기서 p는 참일 확률.

분포는 다음과 같이 그려짐.

<figure>
<img src ="sigmoid.png"><figurecaption>시그모이드 함수 그래프</figurecaption>
</figure>


**시그모이드 함수를 사용해 회귀**를 하면 **로지스틱 회귀**라고 부름(시그모이드 함수는 로지스틱함수라고도 부름)

uni-step-function보다 부드럽게 값을 구분 가능.


#### - Softmax 함수:

다중 분류에서 확률예측에 사용함.

softmax함수는 각 클래스에 대한 확률값을 뜻함.

여기서 클래스란 분류하려고 하는 Categorie를 뜻함.

softmax함수의 조건:

1. $0 ≤ softmax(a) ≤ 1$
2. $\Sigma_{c=1}^{C}softmax(a_c) = 1$

벡터를 입력으로 받아 0과 1사이의 값을 반환. 이때 반환되는 결과값이 확률값임.

입력값에 대해 민감하고, 입력값(logit)을 0~1사이의 값으로 정규화하여 출력함.

e(오일러 함수)를 사용하는 이유:

1. 결과값을 0~1사이의 값으로 정규화 하기 위해서.
2. 미분계산이 쉽기 때문에( $e^x$의 미분은 $e^x$ )
3. $x$의 값이 무엇이든지 간에 0보다 큰 양수가 되기 때문.

$softmax(x_i) = e^{x_i}/\Sigma_{j=1}^Ne^{x_j}$

###### Softmax의 입력값은 logit:

분류문제에서 각 클래스에 대한 logit으로 사용됨.

출력층(마지막 계층)에서 계산된 값을 입력값(logit)으로 사용.

Softmax함수는 mode와 같이 움직임:

mode는 가장 큰 값의 위치를 선택하는 함수.

1. Softmax함수는 가장 큰 logit에 가장 높은 확률을 부여함(승자독식)
    
2. 차이증폭. 입력들간의 차이가 확률로 변환되었을때 더욱 크게 벌어짐.
    
3. Temperture 효과.
    
    온도 = T라고 가정. 이때 T는 분포의 뾰족함을 조절.
    
    $softmax(a/T)_c = 1.0 (c= argmax_c a_c일때), 0.0(그외)$
    
    T가 낮으면 저온. 이때는 가장 가능성이 높은 클래스에 확률이 집중됨(이를 승자독식이라 함)
    
    T가 높으면 고온. 이때는 모든 확률에 질량이 고르게 퍼짐.
    



